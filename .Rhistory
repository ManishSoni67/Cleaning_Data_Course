xml_data[[1]]
xml_data
xml_data[[1]][[1]]
xml_data[[1]]
topxml <- xmlSApply(xml_data[[1]],
function(x) xmlSApply(x, xmlValue))
xml_df <- data.frame(t(topxml),
row.names=NULL)
xml_df
head(xml_df)
dim(xml_df)
nrow(subset(xml_df,zipcode==21231,na.rm=TRUE))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv","pid_file.csv")
?fread
library(datasets)
?fread
install.packages("data.table")
library(data.table)
fread("pid_file.csv")
p_file<- fread("pid_file.csv")
p_file
dim(p_file)
p_file$pwgtp15
p_file$pwgtp15
sum(p_file$pwgtp15)
p_file[,mean(pwgtp15),by=SEX]
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
DT<-p_file
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
rowMeans(DT)[DT$SEX==1]
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
tapply(DT$pwgtp15,DT$SEX,mean)
mean(DT$pwgtp15,by=DT$SEX)
sapply(split(DT$pwgtp15,DT$SEX),mean)
nrow((subset(file, VAL==24, na.rm=TRUE)))
install.packages("RODBC")
library("httr", lib.loc="~/R/win-library/3.3")
source('C:/Users/manis/OneDrive/Corsera/R/github.R')
source('C:/Users/manis/OneDrive/Corsera/R/github.R')
source('C:/Users/manis/OneDrive/Corsera/R/github.R')
con<-url("http://biostat.jhsph.edu/~jleek/contact.html")
lines<- readLines(con)
lines
nchar(lines)
nchar(lines[c(10,20,30,100)])
file<- read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
file<- read.fwf("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
)
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 9)
file
head(line())
head(file)
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 100000)
head(file)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "af2c4ec57fc93a8c4d41",
secret = "b289f186016127e1bfba0f39f4083a6a224c4a79")
myapp
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
gtoken
github_token
req <- with_config(gtoken, GET("https://api.github.com/users/jtleek/repos"))stop_for_status(req)
#content(req)
req <- with_config(gtoken, GET("https://api.github.com/users/jtleek/repos"))
stop_for_status(req)
library(jsonlite)
document<-fromJSON(txt='https://api.github.com/users/jtleek/repos')
document
class(document)
head(document)
document$name
document[document$name=='datasharing']
document[document$name='datasharing']
document[document$name=='datasharing']$created_at
document[document$name=='datasharing']
document[[document$name=='datasharing']
]
document[document[,2]=='datasharing']
subset(document, name=="datasharing",na.rm=TRUE)
subset(document, name=="datasharing",na.rm=TRUE)$created_at
install.packages("sqldf")
lines
nchar(lines[c(10,20,30,100)])
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 1000,header = TRUE,sep = '\t')
file
head(file)
sum(file[3:nrow(file),4])
class(file)
file$Weekly.SST.data.starts.week.centered.on.3Jan1990
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 1000,header = TRUE,sep = '-')
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 1000,header = TRUE,sep = '-',skip = 3)
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 1000,header = TRUE,sep = '/t',skip = 3)
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 1000,header = TRUE,skip = 3)
file
head(file)
dim(file)
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 1000,header = TRUEsep="\t",skip = 3)
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 1000,header = TRUEsep='\t',skip = 3)
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 1000,header = TRUE,sep='\t',skip = 3)
file
head(file)
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = 1000,header = TRUE,sep='\n',skip = 3)
dim(file)
file<- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),widths = c(15, 4, 1, 3, 5, 4), header = FALSE, sep = "\t", skip = 4)
head(file)
sum(file$V6)
library(dplyr)
install.packages("dplyr")
library(dplyr)
file
head(file)
getwd()
chicago<-readRDS("chicago.rds")
dim(chicago)
head(chicago)
select(chicago)
select(chicago, city:dptp)
head(select(chicago, city:dptp))
library(swirl)
swirl()
mydf<- read.csv(path2csv)
mydf<- read.csv(path2csv, stringASFactors=FALSE)
mydf<- read.csv(path2csv, stringAsFactors=FALSE)
mydf<- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
carn <- tbl_df(mydf)
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
select(cran, ip_id[5:20])
s:20
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
asas
asdas
-5:20
-(5:20)
select(cran, -soze)
select(cran, -size)
select(cran, -(X:size))
filter(cran, package=="swirl")
filter(cran, r_version=="3.1.1",country=="US")
?Comparison
filter(cran, r_version=="3.1.1",country=="IN")
filter(cran, r_version<="3.0.2",country=="IN")
filter(cran,country=="IN" | country=="US")
filter(cran, size>100500, r_os=="linux-gnu")
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran, !is.na(r_version))
cran2<- select(cran, size:ip_id)
arrange(cran2,ip_id)
arrange(cran2,desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3<- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb=size/2^20)
mutate(cran3, size_gb=size_mb/2^10)
cran3
mutate(cran3, size_mb=size/2^20, size_gb=size_mb/2^10)
mutate(cran3, correct_size=size-1000)
mutate(cran3, correct_size=size+1000)
summarise(cran, avg_bytes=mean(size))
summarize(cran, avg_bytes=mean(size))
library(dplyr)
library(swirl)
swirl()
library(dplyr)
cran<- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/summarize1.R')
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/summarize1.R')
pack_sum
submit
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts<-filter(pack_sum, package<679)
top_counts<-filter(pack_sum, count()<679)
top_counts<-filter(pack_sum, count>679)
top_counts
View(top_counts)
?arrange
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique>465)
View(top_unique)
top_unique_sorted <- arrange(pack_sum,desc(unique))
top_unique_sorted <- arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit
submit()
View(result3)
submit()
submit)()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
?gather
res <- gather(students2, key= sex_xlass, value=count())
res <- gather(students2, key= sex_xlass, value=count
)
res <- gather(students2, key= sex_xlass, value=count, -grade)
res <- gather(students2, key= sex_class, value=count, -grade)
res
?separate()
?separate
separate(data=res, col = sex_class, into = c("sex", "class"))
submit()
submit()
students3
gather(students3, key = class, value= grade, na.rm = TRUE, convert = TRUE)
submit()
submit()
?spread
submit()
students3 %>%
gather(class, grade, class1:class5, na.rm = TRUE)
submit()
submit()
submit()
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script3.R')
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script3.R')
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script3.R')
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script3.R')
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script3.R')
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script3.R')
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script3.R')
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script3.R')
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script3.R')
submit()
extract_numeric("class5")
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script4.R')
submit()
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script4.R')
submit()
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script4.R')
submit()
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script4.R')
submit()
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script4.R')
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script4.R')
students4
submit
submit()
submit()
submit()
passed
failed
passed
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
bind_rows(passed, failed)
sat
source('C:/Users/manis/AppData/Local/Temp/Rtmpspqxyi/script8.R')
submit()
submit()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv","quiz_3_1.csv")
q_3_1 <- read.csv("quiz_3_1.csv")
head(q_3_1)
dim(q_3_1)
q_3_1$ACR
distinct(q_3_1$ACR)
unique(q_3_1$ACR)
source('C:/Users/manis/OneDrive/Corsera/R/quiz_3_1.R')
agricultureLogical
source('C:/Users/manis/OneDrive/Corsera/R/quiz_3_1.R')
agricultureLogical
agricultureLogical <- q_3_1 %>% filter(ACR>=3 & AGS>=6)
agricultureLogical
which(agricultureLogical)
q_3_1[(ACR>=3 & AGS>=6),]
q_3_1[(q_3_1$ACR>=3 & q_3_1$AGS>=6),]
agricultureLogical <- q_3_1[(ACR>=3 & AGS>=6),]
agricultureLogical <- q_3_1[(q_3_1$ACR>=3 & q_3_1$AGS>=6),]
which(agricultureLogical)
agricultureLogical <- !is.na(agricultureLogical)
which(agricultureLogical)
head(agricultureLogical)
agricultureLogical <- !is.na(q_3_1[(q_3_1$ACR>=3 & q_3_1$AGS>=6),])
agricultureLogical
which(agricultureLogical)
install.packages("jpeg")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg","q_3_2.jpg")
library(jpeg)
file_data <- jpeg("q_3_2.jpg")
class(file_data)
file_data <- jpeg(filename =  "q_3_2.jpg", Native= TRUE)
file_data <- readJPEG("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg", native = TRUE)
file_data <- readJPEG("q_3_2.jpg", native = TRUE)
file_data <- readJPEG(source =  "q_3_2.jpg", native = TRUE)
img.n <- readJPEG(system.file("img", "q_3_2.jpg", package="jpeg"), TRUE)
img.n <- readJPEG(system.file("img", "q_3_2.jpg"), TRUE)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg","q_3_2.jpg")
img.n <- readJPEG(system.file("img", "q_3_2.jpg", package="jpeg"), TRUE)
img.n <- readJPEG(system.file("img", "getdata%2Fjeff.jpg", package="jpeg"), TRUE)
source('C:/Users/manis/OneDrive/Corsera/R/DataCleaning_Q3_2.R')
source('C:/Users/manis/OneDrive/Corsera/R/DataCleaning_Q3_2.R')
source('C:/Users/manis/OneDrive/Corsera/R/DataCleaning_Q3_2.R')
quantile(data2, probs = c(0.3, 0.8))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv","FGDP.csv")
fgdp <- read.csv("FGDP.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv","fedstat.csv")
fedstat <-read.csv("fedstat.csv")
merge(fgdp, fedstat)
head(fgdp)
head(fedstat)
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help("lubridate")
help(package = lubridate)
this_day = today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
minute(this_moment)
ymd("1989-05-17")
my_dat <- ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy("25081985")
dmy(25081985)
dmy("192012")
ymd("192012")
ymd("\\192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
lapply(dt2, ymd)
ymd(dt2)
update(this_moment, hours= 8, minutes =34, seconds=55)
this_moment
this_moment
this_moment = update(this_moment, hours= 10, minutes =16, seconds=0)
this_moment <- update(this_moment, hours= 10, minutes =16, seconds=0)
this_moment
nyc <- now(tzone = "America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hour= 17, minute= 34, seconds=0)
depart <- update(depart, hours= 17, minutes= 34)
depart
arrive < - update(depart, hours= 15, minutes=50)
arrive <- update(depart, hours= 15, minutes=50)
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <-with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = Singapore)
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval(start = last_time, end = arrive)
as.period(how_long)
stopwatch()
getwd()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "/Week_4/Q1.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "Week_4/Q1.csv")
file_data < - read\
file_data < - read.csv("Week_4/Q1.csv")
file_data <- read.csv("Week_4/Q1.csv")
file_data$wgtp1
strsplit(file_data,"wgtp")
strsplit(file_data$wgtp1,"wgtp")
strsplit(file_data,"wgtp")
strsplit(file_data)
strsplit(file_data$WGTP)
file_data$WGTP
names(file_data)
strsplit(names(file_data))[[123]]
strsplit(names(file_data))
strsplit(names(file_data),"wgtp")
strsplit(names(file_data),"wgtp")[123]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", "/Week_4/Q2.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", "Week_4/Q2.csv")
file_data1<- read.csv("Week_4/Q2.csv")
dim(file_data1)
head(file_data1)
strsplit(file_data1$X.2,",")
strsplit(file_data1[$X.2],",")
strsplit(file_data1[$X.2],",")
strsplit(file_data1[3],",")
strsplit(file_data1[3]," ")
head(file_data1$X.2)
head(file_data1$X.3)
file_data1$X.3
file_data1<- read.csv("Week_4/Q2.csv", skip = 4)
file_data1
head(file_data1)
sub(",","", file_data1)
data <- sub(",","", file_data1$X.3)
data
data <- sub(",","", file_data1$X.4)
data
data <- grepl(",", file_data1)
data
data <- grepl(",", file_data1$X.4)
data
data <- gsub(",","",file_data1)
data
data <- gsub(",","",file_data1$X.4)
data
data <- as.numeric( gsub(",","",file_data1$X.4))
data <- as.numeric( gsub(",","",file_data1$X.4),na.rm=TRUE)
data
sum(data, na.rm = TRUE)
mean(data, na.rm = TRUE)
mean(data[1:215], na.rm = TRUE)
head(file_data1)
grep("^United",countryNames), 3
grep("^United",file_data1$X.3), 3
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", "Week_4/Q3.csv")
file_data2<-read.csv("Week_4/Q3.csv")
head(file_data2)
file_data2<-read.csv("Week_4/Q3.csv", skip = 4, nrows = 215)
head(file_data2)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", "Week_4/Q3.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", "Week_4/Q3.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", "Week_4/Q3_2.csv")
file_data2_2<-read.csv("Week_4/Q3_2.csv")
head(file_data2_2)
head(file_data2_2$Short.Name)
file_data2_2$Short.Name
head(file_data2_2$Special.Notes)
m_data <- merge(file_data2, file_data2_2, by = c("CountryCode"), all = TRUE)
setNames(file_data2$X, nm = "CountryCode")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
class(sampleTimes)
sampleTimes[year(sampleTimes)==2012]
sampleTimes[year(sampleTimes)==2012 & wday(sampleTimes, label = TRUE)==2]
sampleTimes[year(sampleTimes)==2012 & wday(sampleTimes)==2]
length(sampleTimes[year(sampleTimes)==2012 & wday(sampleTimes)==2])
length(sampleTimes[year(sampleTimes)==2012])
getwd()
setwd("C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work")
install.packages("reshape2")
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
paste(getwd(),"/UCI HAR Dataset")
paste(getwd(),"/UCI HAR Dataset",sep = "")
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
features <- read.table("UCI HAR Dataset/features.txt")
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
source('C:/Users/manis/OneDrive/Corsera/Data Cleaning/Assignment/Work/run_analysis.R')
data_text <- read.table("tidy.txt")
data_text
dim(data_text)
head(data_text)
